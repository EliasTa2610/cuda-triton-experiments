[9877] online_softmax@127.0.0.1
  online_softmax(const float *, float *, int, int) (1024, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.59
    SM Frequency                    Ghz         1.09
    Elapsed Cycles                cycle        50111
    Memory Throughput                 %        19.65
    DRAM Throughput                   %        19.65
    Duration                         us        45.79
    L1/TEX Cache Throughput           %        16.02
    L2 Cache Throughput               %        32.42
    SM Active Cycles              cycle     45925.92
    Compute (SM) Throughput           %        65.80
    ----------------------- ----------- ------------

    OPT   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis section to see what the   
          compute pipelines are spending their time doing. Also, consider whether any computation is redundant and      
          could be reduced or moved to look-up tables.                                                                  

    Section: GPU Speed Of Light Roofline Chart
    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The workload achieved 15%  
          of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide    
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline      
          analysis.                                                                                                     

    Section: PM Sampling
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Maximum Buffer Size             Mbyte        25.17
    Dropped Samples                sample            0
    Maximum Sampling Interval          us         1.50
    # Pass Groups                                    2
    ------------------------- ----------- ------------

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         2.89
    Executed Ipc Elapsed  inst/cycle         2.63
    Issue Slots Busy               %        72.35
    Issued Ipc Active     inst/cycle         2.89
    SM Busy                        %        72.35
    -------------------- ----------- ------------

    INF   ALU is the highest-utilized pipeline (41.2%) based on active cycles, taking into account the rates of its     
          different instructions. It executes integer and logic operations. It is well-utilized, but should not be a    
          bottleneck.                                                                                                   

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s       400.49
    Mem Busy                               %        15.21
    Max Bandwidth                          %        19.65
    L1/TEX Hit Rate                        %        32.54
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                   525004
    L2 Hit Rate                            %        52.62
    Mem Pipes Busy                         %        26.44
    ---------------------------- ----------- ------------

    Section: Memory Workload Analysis Chart
    OPT   Est. Speedup: 12.3%                                                                                           
          Out of the 16800128.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To       
          increase this success rate, consider marking only those memory regions as compressible that contain the most  
          zero values and/or expose the most homogeneous values.                                                        

    Section: Scheduler Statistics
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    One or More Eligible                   %        72.30
    Issued Warp Per Scheduler                        0.72
    No Eligible                            %        27.70
    Active Warps Per Scheduler          warp        14.63
    Eligible Warps Per Scheduler        warp         4.27
    ---------------------------- ----------- ------------

    Section: Warp State Statistics
    ---------------------------------------- ----------- ------------
    Metric Name                              Metric Unit Metric Value
    ---------------------------------------- ----------- ------------
    Warp Cycles Per Issued Instruction             cycle        20.24
    Warp Cycles Per Executed Instruction           cycle        20.26
    Avg. Active Threads Per Warp                                31.72
    Avg. Not Predicated Off Threads Per Warp                    30.33
    ---------------------------------------- ----------- ------------

    Section: Instruction Statistics
    ---------------------------------------- ----------- ------------
    Metric Name                              Metric Unit Metric Value
    ---------------------------------------- ----------- ------------
    Avg. Executed Instructions Per Scheduler        inst     33201.40
    Executed Instructions                           inst     15139840
    Avg. Issued Instructions Per Scheduler          inst     33225.40
    Issued Instructions                             inst     15150781
    ---------------------------------------- ----------- ------------

    OPT   Est. Speedup: 4.467%                                                                                          
          This kernel executes 2691072 fused and 1437696 non-fused FP32 instructions. By converting pairs of non-fused  
          instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point),           
          higher-throughput equivalent, the achieved FP32 performance could be increased by up to 17% (relative to its  
          current performance). Check the Source page to identify where this kernel executes FP32 instructions.         

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   1024
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block            8.19
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             114
    Stack Size                                                  1024
    Threads                                   thread         1048576
    # TPCs                                                        57
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                4.49
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 20%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 112 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, this partial wave may account for  
          up to 20.0% of the total runtime of this kernel. Try launching a grid with no partial wave. The overall       
          impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware   
          Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for     
          more details on launch configurations.                                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Max Active Clusters                 cluster            0
    Max Cluster Size                      block            8
    Overall GPU Occupancy                     %            0
    Cluster Occupancy                         %            0
    Block Limit Barriers                  block           32
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        91.69
    Achieved Active Warps Per SM           warp        58.68
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle     14327.40
    Total DRAM Elapsed Cycles        cycle      2915840
    Average L1 Active Cycles         cycle     45925.92
    Total L1 Elapsed Cycles          cycle      5756270
    Average L2 Active Cycles         cycle     32299.91
    Total L2 Elapsed Cycles          cycle      3987520
    Average SM Active Cycles         cycle     45925.92
    Total SM Elapsed Cycles          cycle      5756270
    Average SMSP Active Cycles       cycle     45952.44
    Total SMSP Elapsed Cycles        cycle     23025080
    -------------------------- ----------- ------------

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.14
    Branch Instructions              inst      2135040
    Branch Efficiency                   %        99.64
    Avg. Divergent Branches                      11.23
    ------------------------- ----------- ------------

